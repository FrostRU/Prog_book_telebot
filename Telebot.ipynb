{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd8ccfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install telebot\n",
    "#!pip install torch\n",
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dd802b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Huawey\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import requests\n",
    "import telebot\n",
    "from telebot import types\n",
    "import linecache\n",
    "import urllib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from nltk.tokenize import (\n",
    "    sent_tokenize,\n",
    "    word_tokenize,\n",
    "    TweetTokenizer,\n",
    "    WordPunctTokenizer,\n",
    "    WhitespaceTokenizer,\n",
    "    LegalitySyllableTokenizer,\n",
    "    SyllableTokenizer,\n",
    ")\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "from tqdm.notebook import tqdm\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8507247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Huawey\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Huawey\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:From C:\\Users\\Huawey\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Huawey\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "75/75 - 2s - loss: 0.6159 - accuracy: 0.1050 - val_loss: 0.4918 - val_accuracy: 0.1335 - 2s/epoch - 23ms/step\n",
      "Epoch 2/60\n",
      "75/75 - 0s - loss: 0.4147 - accuracy: 0.1300 - val_loss: 0.3819 - val_accuracy: 0.1335 - 211ms/epoch - 3ms/step\n",
      "Epoch 3/60\n",
      "75/75 - 0s - loss: 0.3784 - accuracy: 0.1200 - val_loss: 0.3764 - val_accuracy: 0.1335 - 206ms/epoch - 3ms/step\n",
      "Epoch 4/60\n",
      "75/75 - 0s - loss: 0.3762 - accuracy: 0.1333 - val_loss: 0.3753 - val_accuracy: 0.1033 - 200ms/epoch - 3ms/step\n",
      "Epoch 5/60\n",
      "75/75 - 0s - loss: 0.3761 - accuracy: 0.1383 - val_loss: 0.3751 - val_accuracy: 0.1033 - 171ms/epoch - 2ms/step\n",
      "Epoch 6/60\n",
      "75/75 - 0s - loss: 0.3757 - accuracy: 0.1533 - val_loss: 0.3758 - val_accuracy: 0.1033 - 206ms/epoch - 3ms/step\n",
      "Epoch 7/60\n",
      "75/75 - 0s - loss: 0.3757 - accuracy: 0.1467 - val_loss: 0.3755 - val_accuracy: 0.1033 - 223ms/epoch - 3ms/step\n",
      "Epoch 8/60\n",
      "75/75 - 0s - loss: 0.3749 - accuracy: 0.1483 - val_loss: 0.3748 - val_accuracy: 0.2141 - 210ms/epoch - 3ms/step\n",
      "Epoch 9/60\n",
      "75/75 - 0s - loss: 0.3735 - accuracy: 0.1667 - val_loss: 0.3731 - val_accuracy: 0.1033 - 255ms/epoch - 3ms/step\n",
      "Epoch 10/60\n",
      "75/75 - 0s - loss: 0.3725 - accuracy: 0.1733 - val_loss: 0.3717 - val_accuracy: 0.2343 - 279ms/epoch - 4ms/step\n",
      "Epoch 11/60\n",
      "75/75 - 0s - loss: 0.3702 - accuracy: 0.1783 - val_loss: 0.3688 - val_accuracy: 0.1864 - 229ms/epoch - 3ms/step\n",
      "Epoch 12/60\n",
      "75/75 - 0s - loss: 0.3658 - accuracy: 0.2367 - val_loss: 0.3636 - val_accuracy: 0.1562 - 248ms/epoch - 3ms/step\n",
      "Epoch 13/60\n",
      "75/75 - 0s - loss: 0.3531 - accuracy: 0.3183 - val_loss: 0.3441 - val_accuracy: 0.2695 - 262ms/epoch - 3ms/step\n",
      "Epoch 14/60\n",
      "75/75 - 0s - loss: 0.3260 - accuracy: 0.2650 - val_loss: 0.3113 - val_accuracy: 0.2670 - 220ms/epoch - 3ms/step\n",
      "Epoch 15/60\n",
      "75/75 - 0s - loss: 0.2933 - accuracy: 0.3350 - val_loss: 0.2851 - val_accuracy: 0.3753 - 216ms/epoch - 3ms/step\n",
      "Epoch 16/60\n",
      "75/75 - 0s - loss: 0.2746 - accuracy: 0.3650 - val_loss: 0.2700 - val_accuracy: 0.4912 - 278ms/epoch - 4ms/step\n",
      "Epoch 17/60\n",
      "75/75 - 0s - loss: 0.2638 - accuracy: 0.5617 - val_loss: 0.2600 - val_accuracy: 0.7557 - 265ms/epoch - 4ms/step\n",
      "Epoch 18/60\n",
      "75/75 - 0s - loss: 0.2526 - accuracy: 0.7100 - val_loss: 0.2491 - val_accuracy: 0.7003 - 200ms/epoch - 3ms/step\n",
      "Epoch 19/60\n",
      "75/75 - 0s - loss: 0.2404 - accuracy: 0.7250 - val_loss: 0.2351 - val_accuracy: 0.6574 - 188ms/epoch - 3ms/step\n",
      "Epoch 20/60\n",
      "75/75 - 0s - loss: 0.2191 - accuracy: 0.8617 - val_loss: 0.2091 - val_accuracy: 0.7683 - 219ms/epoch - 3ms/step\n",
      "Epoch 21/60\n",
      "75/75 - 0s - loss: 0.1871 - accuracy: 0.9000 - val_loss: 0.1756 - val_accuracy: 0.9496 - 260ms/epoch - 3ms/step\n",
      "Epoch 22/60\n",
      "75/75 - 0s - loss: 0.1528 - accuracy: 0.9967 - val_loss: 0.1383 - val_accuracy: 0.9950 - 319ms/epoch - 4ms/step\n",
      "Epoch 23/60\n",
      "75/75 - 0s - loss: 0.1222 - accuracy: 1.0000 - val_loss: 0.1091 - val_accuracy: 1.0000 - 240ms/epoch - 3ms/step\n",
      "Epoch 24/60\n",
      "75/75 - 0s - loss: 0.0952 - accuracy: 0.9967 - val_loss: 0.0835 - val_accuracy: 0.9924 - 240ms/epoch - 3ms/step\n",
      "Epoch 25/60\n",
      "75/75 - 0s - loss: 0.0729 - accuracy: 0.9967 - val_loss: 0.0627 - val_accuracy: 1.0000 - 257ms/epoch - 3ms/step\n",
      "Epoch 26/60\n",
      "75/75 - 0s - loss: 0.0530 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 1.0000 - 262ms/epoch - 3ms/step\n",
      "Epoch 27/60\n",
      "75/75 - 0s - loss: 0.0380 - accuracy: 1.0000 - val_loss: 0.0328 - val_accuracy: 1.0000 - 259ms/epoch - 3ms/step\n",
      "Epoch 28/60\n",
      "75/75 - 0s - loss: 0.0274 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 1.0000 - 246ms/epoch - 3ms/step\n",
      "Epoch 29/60\n",
      "75/75 - 0s - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 1.0000 - 238ms/epoch - 3ms/step\n",
      "Epoch 30/60\n",
      "75/75 - 0s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 1.0000 - 230ms/epoch - 3ms/step\n",
      "Epoch 31/60\n",
      "75/75 - 0s - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 1.0000 - 217ms/epoch - 3ms/step\n",
      "Epoch 32/60\n",
      "75/75 - 0s - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000 - 228ms/epoch - 3ms/step\n",
      "Epoch 33/60\n",
      "75/75 - 0s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000 - 232ms/epoch - 3ms/step\n",
      "Epoch 34/60\n",
      "75/75 - 0s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000 - 225ms/epoch - 3ms/step\n",
      "Epoch 35/60\n",
      "75/75 - 0s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000 - 228ms/epoch - 3ms/step\n",
      "Epoch 36/60\n",
      "75/75 - 0s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000 - 215ms/epoch - 3ms/step\n",
      "Epoch 37/60\n",
      "75/75 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000 - 198ms/epoch - 3ms/step\n",
      "Epoch 38/60\n",
      "75/75 - 0s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000 - 205ms/epoch - 3ms/step\n",
      "Epoch 39/60\n",
      "75/75 - 0s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000 - 175ms/epoch - 2ms/step\n",
      "Epoch 40/60\n",
      "75/75 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000 - 171ms/epoch - 2ms/step\n",
      "Epoch 41/60\n",
      "75/75 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000 - 167ms/epoch - 2ms/step\n",
      "Epoch 42/60\n",
      "75/75 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000 - 164ms/epoch - 2ms/step\n",
      "Epoch 43/60\n",
      "75/75 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000 - 181ms/epoch - 2ms/step\n",
      "Epoch 44/60\n",
      "75/75 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000 - 159ms/epoch - 2ms/step\n",
      "Epoch 45/60\n",
      "75/75 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000 - 165ms/epoch - 2ms/step\n",
      "Epoch 46/60\n",
      "75/75 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000 - 182ms/epoch - 2ms/step\n",
      "Epoch 47/60\n",
      "75/75 - 0s - loss: 9.8631e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000 - 171ms/epoch - 2ms/step\n",
      "Epoch 48/60\n",
      "75/75 - 0s - loss: 8.9679e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000 - 157ms/epoch - 2ms/step\n",
      "Epoch 49/60\n",
      "75/75 - 0s - loss: 8.1472e-04 - accuracy: 1.0000 - val_loss: 8.8743e-04 - val_accuracy: 1.0000 - 182ms/epoch - 2ms/step\n",
      "Epoch 50/60\n",
      "75/75 - 0s - loss: 7.4089e-04 - accuracy: 1.0000 - val_loss: 8.1159e-04 - val_accuracy: 1.0000 - 178ms/epoch - 2ms/step\n",
      "Epoch 51/60\n",
      "75/75 - 0s - loss: 6.7573e-04 - accuracy: 1.0000 - val_loss: 7.7658e-04 - val_accuracy: 1.0000 - 158ms/epoch - 2ms/step\n",
      "Epoch 52/60\n",
      "75/75 - 0s - loss: 6.1931e-04 - accuracy: 1.0000 - val_loss: 6.8268e-04 - val_accuracy: 1.0000 - 167ms/epoch - 2ms/step\n",
      "Epoch 53/60\n",
      "75/75 - 0s - loss: 5.7156e-04 - accuracy: 1.0000 - val_loss: 6.2958e-04 - val_accuracy: 1.0000 - 175ms/epoch - 2ms/step\n",
      "Epoch 54/60\n",
      "75/75 - 0s - loss: 5.2558e-04 - accuracy: 1.0000 - val_loss: 6.0357e-04 - val_accuracy: 1.0000 - 171ms/epoch - 2ms/step\n",
      "Epoch 55/60\n",
      "75/75 - 0s - loss: 4.8187e-04 - accuracy: 1.0000 - val_loss: 5.3654e-04 - val_accuracy: 1.0000 - 168ms/epoch - 2ms/step\n",
      "Epoch 56/60\n",
      "75/75 - 0s - loss: 4.4737e-04 - accuracy: 1.0000 - val_loss: 5.1736e-04 - val_accuracy: 1.0000 - 164ms/epoch - 2ms/step\n",
      "Epoch 57/60\n",
      "75/75 - 0s - loss: 4.1439e-04 - accuracy: 1.0000 - val_loss: 4.6152e-04 - val_accuracy: 1.0000 - 160ms/epoch - 2ms/step\n",
      "Epoch 58/60\n",
      "75/75 - 0s - loss: 3.8214e-04 - accuracy: 1.0000 - val_loss: 4.2001e-04 - val_accuracy: 1.0000 - 196ms/epoch - 3ms/step\n",
      "Epoch 59/60\n",
      "75/75 - 0s - loss: 3.5439e-04 - accuracy: 1.0000 - val_loss: 3.9603e-04 - val_accuracy: 1.0000 - 174ms/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/60\n",
      "75/75 - 0s - loss: 3.2889e-04 - accuracy: 1.0000 - val_loss: 3.6773e-04 - val_accuracy: 1.0000 - 187ms/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "with zipfile.ZipFile('Bookclass.zip', 'r') as z: z.extractall()\n",
    "with zipfile.ZipFile('data.zip', 'r') as z: z.extractall()\n",
    "def func(path):\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        contents = f.readlines()\n",
    "        a,b=int(contents[0].split(',')[1][2]),int(contents[0].split(',')[2][0])\n",
    "    for i in range(len(contents)):\n",
    "        contents[i]=contents[i].split(',')[0]\n",
    "    df=pd.DataFrame([contents]).T\n",
    "    df[1]=[a]*df.shape[0]\n",
    "    df[2]=[b]*df.shape[0]\n",
    "    return df\n",
    "tmp=os.listdir('data')\n",
    "df=pd.DataFrame([])\n",
    "for i in tmp:\n",
    "    for j in os.listdir(u'data/'+i):\n",
    "        if j != u'.ipynb_checkpoints':\n",
    "            df=pd.concat([df,func(u'data/'+i+'/'+j)],axis=0,ignore_index=True)\n",
    "df=df.sample(frac=1)\n",
    "xtraining_data=df[0].iloc[0:600].reset_index(drop=True)\n",
    "xtest_data=df[0].iloc[600:-1].reset_index(drop=True)\n",
    "def classer(x):\n",
    "    len = x.shape[0]\n",
    "    classes=8\n",
    "    a=pd.DataFrame([])\n",
    "    for i in x:\n",
    "        c=i\n",
    "        tmp=pd.DataFrame(np.zeros(8)).T\n",
    "        tmp[c]=1\n",
    "        a=pd.concat([a,tmp],axis=0,ignore_index=True)\n",
    "    return a.reset_index(drop=True)\n",
    "ytraining_data1=df[1].iloc[0:600].reset_index(drop=True)\n",
    "ytest_data1=df[1].iloc[600:-1].reset_index(drop=True)\n",
    "ytraining_data2=df[2].iloc[0:600].reset_index(drop=True)\n",
    "ytest_data2=df[2].iloc[600:-1].reset_index(drop=True)\n",
    "ytraining_data1=classer(ytraining_data1)\n",
    "ytraining_data2=classer(ytraining_data2)\n",
    "ytest_data1=classer(ytest_data1)\n",
    "ytest_data2=classer(ytest_data2)\n",
    "def Token(xtr):\n",
    "    tokenizer=Tokenizer(num_words=1000,oov_token='<OOV>')\n",
    "    tokenizer.fit_on_texts(df[0])\n",
    "    word_index=tokenizer.word_index\n",
    "    training_seq=tokenizer.texts_to_sequences(xtr)\n",
    "    training_padded=pad_sequences(training_seq,maxlen=30,padding='post',truncating='post')\n",
    "    return training_padded\n",
    "test_padded=Token(xtest_data)\n",
    "training_padded=Token(xtraining_data)\n",
    "model_lang = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(1000, 30, input_length=30),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(8, activation='softmax')\n",
    "])\n",
    "model_lang.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "history = model_lang.fit(training_padded, ytraining_data1, epochs=60, validation_data=(test_padded, ytest_data1), verbose=2,batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55473c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "75/75 - 1s - loss: 0.5859 - accuracy: 0.1700 - val_loss: 0.4145 - val_accuracy: 0.2217 - 1s/epoch - 17ms/step\n",
      "Epoch 2/60\n",
      "75/75 - 0s - loss: 0.3485 - accuracy: 0.3133 - val_loss: 0.3062 - val_accuracy: 0.3526 - 180ms/epoch - 2ms/step\n",
      "Epoch 3/60\n",
      "75/75 - 0s - loss: 0.2962 - accuracy: 0.3500 - val_loss: 0.2845 - val_accuracy: 0.3526 - 176ms/epoch - 2ms/step\n",
      "Epoch 4/60\n",
      "75/75 - 0s - loss: 0.2824 - accuracy: 0.3500 - val_loss: 0.2803 - val_accuracy: 0.3526 - 175ms/epoch - 2ms/step\n",
      "Epoch 5/60\n",
      "75/75 - 0s - loss: 0.2796 - accuracy: 0.3500 - val_loss: 0.2781 - val_accuracy: 0.3526 - 179ms/epoch - 2ms/step\n",
      "Epoch 6/60\n",
      "75/75 - 0s - loss: 0.2784 - accuracy: 0.3500 - val_loss: 0.2774 - val_accuracy: 0.3526 - 180ms/epoch - 2ms/step\n",
      "Epoch 7/60\n",
      "75/75 - 0s - loss: 0.2775 - accuracy: 0.3500 - val_loss: 0.2765 - val_accuracy: 0.3526 - 175ms/epoch - 2ms/step\n",
      "Epoch 8/60\n",
      "75/75 - 0s - loss: 0.2774 - accuracy: 0.3500 - val_loss: 0.2776 - val_accuracy: 0.3526 - 180ms/epoch - 2ms/step\n",
      "Epoch 9/60\n",
      "75/75 - 0s - loss: 0.2776 - accuracy: 0.3500 - val_loss: 0.2768 - val_accuracy: 0.3526 - 177ms/epoch - 2ms/step\n",
      "Epoch 10/60\n",
      "75/75 - 0s - loss: 0.2761 - accuracy: 0.3500 - val_loss: 0.2745 - val_accuracy: 0.3526 - 177ms/epoch - 2ms/step\n",
      "Epoch 11/60\n",
      "75/75 - 0s - loss: 0.2746 - accuracy: 0.3500 - val_loss: 0.2728 - val_accuracy: 0.3526 - 168ms/epoch - 2ms/step\n",
      "Epoch 12/60\n",
      "75/75 - 0s - loss: 0.2716 - accuracy: 0.3500 - val_loss: 0.2689 - val_accuracy: 0.3526 - 181ms/epoch - 2ms/step\n",
      "Epoch 13/60\n",
      "75/75 - 0s - loss: 0.2648 - accuracy: 0.3583 - val_loss: 0.2598 - val_accuracy: 0.3804 - 183ms/epoch - 2ms/step\n",
      "Epoch 14/60\n",
      "75/75 - 0s - loss: 0.2496 - accuracy: 0.4767 - val_loss: 0.2384 - val_accuracy: 0.5189 - 176ms/epoch - 2ms/step\n",
      "Epoch 15/60\n",
      "75/75 - 0s - loss: 0.2204 - accuracy: 0.5617 - val_loss: 0.2068 - val_accuracy: 0.5416 - 174ms/epoch - 2ms/step\n",
      "Epoch 16/60\n",
      "75/75 - 0s - loss: 0.1891 - accuracy: 0.5817 - val_loss: 0.1844 - val_accuracy: 0.5743 - 178ms/epoch - 2ms/step\n",
      "Epoch 17/60\n",
      "75/75 - 0s - loss: 0.1705 - accuracy: 0.6733 - val_loss: 0.1669 - val_accuracy: 0.6650 - 218ms/epoch - 3ms/step\n",
      "Epoch 18/60\n",
      "75/75 - 0s - loss: 0.1511 - accuracy: 0.7500 - val_loss: 0.1504 - val_accuracy: 0.7783 - 222ms/epoch - 3ms/step\n",
      "Epoch 19/60\n",
      "75/75 - 0s - loss: 0.1342 - accuracy: 0.8600 - val_loss: 0.1287 - val_accuracy: 0.9093 - 192ms/epoch - 3ms/step\n",
      "Epoch 20/60\n",
      "75/75 - 0s - loss: 0.1149 - accuracy: 0.9383 - val_loss: 0.1145 - val_accuracy: 0.9295 - 201ms/epoch - 3ms/step\n",
      "Epoch 21/60\n",
      "75/75 - 0s - loss: 0.0975 - accuracy: 0.9583 - val_loss: 0.0937 - val_accuracy: 0.9547 - 194ms/epoch - 3ms/step\n",
      "Epoch 22/60\n",
      "75/75 - 0s - loss: 0.0805 - accuracy: 0.9700 - val_loss: 0.0771 - val_accuracy: 0.9521 - 187ms/epoch - 2ms/step\n",
      "Epoch 23/60\n",
      "75/75 - 0s - loss: 0.0674 - accuracy: 0.9700 - val_loss: 0.0628 - val_accuracy: 0.9723 - 177ms/epoch - 2ms/step\n",
      "Epoch 24/60\n",
      "75/75 - 0s - loss: 0.0523 - accuracy: 0.9833 - val_loss: 0.0501 - val_accuracy: 0.9748 - 178ms/epoch - 2ms/step\n",
      "Epoch 25/60\n",
      "75/75 - 0s - loss: 0.0409 - accuracy: 0.9900 - val_loss: 0.0394 - val_accuracy: 0.9748 - 183ms/epoch - 2ms/step\n",
      "Epoch 26/60\n",
      "75/75 - 0s - loss: 0.0320 - accuracy: 0.9900 - val_loss: 0.0308 - val_accuracy: 0.9748 - 193ms/epoch - 3ms/step\n",
      "Epoch 27/60\n",
      "75/75 - 0s - loss: 0.0244 - accuracy: 0.9933 - val_loss: 0.0249 - val_accuracy: 0.9874 - 175ms/epoch - 2ms/step\n",
      "Epoch 28/60\n",
      "75/75 - 0s - loss: 0.0195 - accuracy: 0.9933 - val_loss: 0.0191 - val_accuracy: 0.9874 - 176ms/epoch - 2ms/step\n",
      "Epoch 29/60\n",
      "75/75 - 0s - loss: 0.0153 - accuracy: 0.9933 - val_loss: 0.0158 - val_accuracy: 0.9950 - 184ms/epoch - 2ms/step\n",
      "Epoch 30/60\n",
      "75/75 - 0s - loss: 0.0124 - accuracy: 0.9983 - val_loss: 0.0132 - val_accuracy: 0.9924 - 182ms/epoch - 2ms/step\n",
      "Epoch 31/60\n",
      "75/75 - 0s - loss: 0.0102 - accuracy: 0.9967 - val_loss: 0.0107 - val_accuracy: 1.0000 - 183ms/epoch - 2ms/step\n",
      "Epoch 32/60\n",
      "75/75 - 0s - loss: 0.0086 - accuracy: 0.9983 - val_loss: 0.0091 - val_accuracy: 1.0000 - 181ms/epoch - 2ms/step\n",
      "Epoch 33/60\n",
      "75/75 - 0s - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.0080 - val_accuracy: 1.0000 - 179ms/epoch - 2ms/step\n",
      "Epoch 34/60\n",
      "75/75 - 0s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000 - 177ms/epoch - 2ms/step\n",
      "Epoch 35/60\n",
      "75/75 - 0s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000 - 195ms/epoch - 3ms/step\n",
      "Epoch 36/60\n",
      "75/75 - 0s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000 - 181ms/epoch - 2ms/step\n",
      "Epoch 37/60\n",
      "75/75 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000 - 173ms/epoch - 2ms/step\n",
      "Epoch 38/60\n",
      "75/75 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000 - 180ms/epoch - 2ms/step\n",
      "Epoch 39/60\n",
      "75/75 - 0s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000 - 178ms/epoch - 2ms/step\n",
      "Epoch 40/60\n",
      "75/75 - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000 - 172ms/epoch - 2ms/step\n",
      "Epoch 41/60\n",
      "75/75 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000 - 175ms/epoch - 2ms/step\n",
      "Epoch 42/60\n",
      "75/75 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000 - 172ms/epoch - 2ms/step\n",
      "Epoch 43/60\n",
      "75/75 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000 - 191ms/epoch - 3ms/step\n",
      "Epoch 44/60\n",
      "75/75 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000 - 183ms/epoch - 2ms/step\n",
      "Epoch 45/60\n",
      "75/75 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000 - 173ms/epoch - 2ms/step\n",
      "Epoch 46/60\n",
      "75/75 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000 - 182ms/epoch - 2ms/step\n",
      "Epoch 47/60\n",
      "75/75 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000 - 175ms/epoch - 2ms/step\n",
      "Epoch 48/60\n",
      "75/75 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000 - 187ms/epoch - 2ms/step\n",
      "Epoch 49/60\n",
      "75/75 - 0s - loss: 9.9386e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000 - 189ms/epoch - 3ms/step\n",
      "Epoch 50/60\n",
      "75/75 - 0s - loss: 8.9293e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000 - 184ms/epoch - 2ms/step\n",
      "Epoch 51/60\n",
      "75/75 - 0s - loss: 8.4114e-04 - accuracy: 1.0000 - val_loss: 9.8647e-04 - val_accuracy: 1.0000 - 179ms/epoch - 2ms/step\n",
      "Epoch 52/60\n",
      "75/75 - 0s - loss: 7.6250e-04 - accuracy: 1.0000 - val_loss: 8.8700e-04 - val_accuracy: 1.0000 - 194ms/epoch - 3ms/step\n",
      "Epoch 53/60\n",
      "75/75 - 0s - loss: 6.9217e-04 - accuracy: 1.0000 - val_loss: 8.0218e-04 - val_accuracy: 1.0000 - 193ms/epoch - 3ms/step\n",
      "Epoch 54/60\n",
      "75/75 - 0s - loss: 6.3942e-04 - accuracy: 1.0000 - val_loss: 8.7583e-04 - val_accuracy: 1.0000 - 187ms/epoch - 2ms/step\n",
      "Epoch 55/60\n",
      "75/75 - 0s - loss: 6.0271e-04 - accuracy: 1.0000 - val_loss: 6.8234e-04 - val_accuracy: 1.0000 - 194ms/epoch - 3ms/step\n",
      "Epoch 56/60\n",
      "75/75 - 0s - loss: 5.4727e-04 - accuracy: 1.0000 - val_loss: 7.1523e-04 - val_accuracy: 1.0000 - 189ms/epoch - 3ms/step\n",
      "Epoch 57/60\n",
      "75/75 - 0s - loss: 5.2977e-04 - accuracy: 1.0000 - val_loss: 5.8207e-04 - val_accuracy: 1.0000 - 199ms/epoch - 3ms/step\n",
      "Epoch 58/60\n",
      "75/75 - 0s - loss: 4.5440e-04 - accuracy: 1.0000 - val_loss: 5.5099e-04 - val_accuracy: 1.0000 - 179ms/epoch - 2ms/step\n",
      "Epoch 59/60\n",
      "75/75 - 0s - loss: 4.3158e-04 - accuracy: 1.0000 - val_loss: 5.0120e-04 - val_accuracy: 1.0000 - 191ms/epoch - 3ms/step\n",
      "Epoch 60/60\n",
      "75/75 - 0s - loss: 4.0512e-04 - accuracy: 1.0000 - val_loss: 4.7773e-04 - val_accuracy: 1.0000 - 187ms/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "model_book = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(1000, 30, input_length=30),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(8, activation='softmax')\n",
    "])\n",
    "model_book.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "history2 = model_book.fit(training_padded, ytraining_data2, epochs=60, validation_data=(test_padded, ytest_data2), verbose=2,batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "547ec157",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame([])\n",
    "for j in range(1, 8):\n",
    "    with open('Bookclass/Class book'+str(j)+'.txt', encoding='utf-8') as f:\n",
    "        contents = f.readlines()\n",
    "    bookdf=pd.DataFrame([contents]).T\n",
    "    for i in range(len(contents)):\n",
    "        bookdf.loc[i, 1]=contents[i][-5]\n",
    "        bookdf.loc[i, 2]=contents[i][-3]\n",
    "        bookdf.loc[i, 0]=contents[i][:-7]\n",
    "    tmp=pd.concat([tmp,bookdf],axis=0,ignore_index=True)\n",
    "bookdf = tmp\n",
    "bookdf\n",
    "def getstats(text):\n",
    "    text=pd.DataFrame([text])\n",
    "    text=text[0]\n",
    "    predicted_categories = model_book.predict(Token(text))\n",
    "    predicted_categories2 = model_lang.predict(Token(text))\n",
    "    lvldf = pd.DataFrame(predicted_categories.T)\n",
    "    lngdf = pd.DataFrame(predicted_categories2.T)\n",
    "    max_index = lvldf[0].idxmax()\n",
    "    max_index2 = lngdf[0].idxmax()\n",
    "    if max_index == 0 and max_index2 == 0:\n",
    "        return [-1, -1]\n",
    "    return max_index2, max_index\n",
    "def getbook(max_index2, max_index):\n",
    "    tmpdf = []\n",
    "    for i in range(len(bookdf)):\n",
    "        if bookdf[1][i] == str(max_index2) and bookdf[2][i] == str(max_index):\n",
    "            tmpdf.append(bookdf[0][i])\n",
    "        if max_index == 0 and bookdf[1][i] == str(max_index2):\n",
    "            tmpdf.append(bookdf[0][i])\n",
    "        if max_index2 == 0 and bookdf[2][i] == str(max_index):\n",
    "            tmpdf.append(bookdf[0][i])\n",
    "        if max_index == -1 and max_index2 == -1:\n",
    "            return \"Язык отсутствует в базе данных или неверный ввод\"\n",
    "    return random.choice(tmpdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5dfed96",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = '6694685357:AAHxLH1pdqKvxu_WnfcnMFmeJGzw7M5d6Ps'\n",
    "bot = telebot.TeleBot(TOKEN)\n",
    "@bot.message_handler(commands=['start'])\n",
    "def start(message):\n",
    "    markup = types.ReplyKeyboardMarkup(resize_keyboard = True)\n",
    "    bot.send_message(message.chat.id, 'Привет, {0.first_name}, это ITBot, он поможет вам найти книги для узучения языков программирования.'.format(message.from_user), reply_markup = markup)\n",
    "@bot.message_handler(content_types=['text'])\n",
    "def bot_message(message):\n",
    "    msgdata = getstats(message.text)\n",
    "    bot.send_message(message.chat.id, 'Вот книга для изучения языка по вашему запросу: '+ getbook(msgdata[0], msgdata[1]), disable_web_page_preview=True)\n",
    "bot.polling(none_stop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a94c73e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
